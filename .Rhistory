swirl()
installed.packages(swirl)
install.packages(swirl)
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
rtoold
rtools
install.packages("rtools")
install.packages("swirl")
install.packages("swirl")
install.packages("dpylr")
install.packages("dplyr")
require(dplyr)
install.packages("data.table")
install.packages("swirl")
pollutantmean <- function(directory, pollutant, id = 1:332)
{
fileList <- list.files(path=directory, pattern = ".csv", full.names = TRUE)
values <- numeric()
for(i in id)
{
data <- read.csv(filelist[i])
values <- c(values, data[[pollutant]])
}
mean(values, na.rm = TRUE)
}
pollutantmean("E:\coursera\ds specialization\course 2 r programming\specdata", "sulphate")
pollutantmean("E:/coursera/ds specialization/course 2 r programming/specdata", "sulphate")
pollutantmean("E:/coursera/ds specialization/course 2 r programming/specdata", "sulphate")
pollutantmean <- function(directory, pollutant, id = 1:332)
{
fileList <- list.files(path=directory, pattern = ".csv", full.names = TRUE)
values <- numeric()
for(i in id)
{
data <- read.table(filelist[i])
values <- c(values, data[[pollutant]])
}
mean(values, na.rm = TRUE)
}
pollutantmean("E:/coursera/ds specialization/course 2 r programming/specdata", "sulphate")
pollutantmean <- function(directory, pollutant, id = 1:332)
{
filelist <- list.files(path=directory, pattern = ".csv", full.names = TRUE)
values <- numeric()
for(i in id)
{
data <- read.table(filelist[i])
values <- c(values, data[[pollutant]])
}
mean(values, na.rm = TRUE)
}
pollutantmean("E:/coursera/ds specialization/course 2 r programming/specdata", "sulphate")
pollutantmean("E:/coursera/ds specialization/course 2 r programming/specdata", "sulfate")
pollutantmean <- function(directory, pollutant, id = 1:332)
{
filelist <- list.files(path=directory, pattern = ".csv", full.names = TRUE)
values <- numeric()
for(i in id)
{
data <- read.csv(filelist[i])
values <- c(values, data[[pollutant]])
}
mean(values, na.rm = TRUE)
}
pollutantmean("E:/coursera/ds specialization/course 2 r programming/specdata", "sulfate")
pollutantmean("specdata", "sulfate")
pollutantmean("E:/coursera/ds specialization/course 2 r programming/specdata", "sulfate")
pollutantmean("E:/coursera/ds specialization/course 2 r programming/specdata", "sulfate", 1:10)
pollutantmean <- function(directory, pollutant, id = 1:332)
{
filelist <- list.files(path="E:/coursera/ds specialization/course 2 r programming/specdata", pattern = ".csv", full.names = TRUE)
values <- numeric()
for(i in id)
{
data <- read.csv(filelist[i])
values <- c(values, data[[pollutant]])
}
mean(values, na.rm = TRUE)
}
pollutantmean("specdata", "sulfate", 1:10)
pollutantmean("specdata", "sulfate", 21)
quit
library(datasets)
data("iris")
?iris
round(mean(iris[which(iris$Species == "virginica"),]$Sepal.Length))round(mean(iris[which(iris$Species == "virginica"),]$Sepal.Length))
round(mean(iris[which(iris$Species == "virginica"),]$Sepal.Length))
apply(iris[, 1:4], 2, mean)
data(mtcars)
?mtcars
with(mtcars, tapply(mpg, cyl, mean))
sapply(mtcars,cyl,mean)
split(mtcars,mtcars$cyl)
lapply(mtcars,mean)
new <- tapply(mtcars$hp, mtcars$cyl, mean)
round(abs(new[3]-new[1]))
debug(ls)
ls
quit
exit
q
e
p
jkbj
jkbj]j;kbhjb
l
q
Q
c
c
## functions to cache the inverse of a matrix
## This function creates a special “matrix” object that can cache its inverse
makeCacheMatrix <- function(x = matrix())
{
inv <- NULL
set <- function(y)
{
x <<- y
inv <<- NULL
}
get <- function() x
setInverse <- function(solveMatrix) inv <<- solveMatrix
getInverse <- function() inv
list(set = set, get = get, setInverse = setInverse, getInverse = getInverse)
}
## This function computes the inverse of the special "matrix" returned by makeCacheMatrix function above
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
inv <- x$getInverse()
if(!is.null(inv)){
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data)
x$setInverse(inv)
inv
}
m <- matrix(rnorm(16),4,4)
m1 <- makeCacheMatrix(m)
cacheSolve(m1)
## functions to cache the inverse of a matrix
## This function creates a special “matrix” object that can cache its inverse
makeCacheMatrix <- function(x = matrix())
{
inv <- NULL
set <- function(y)
{
x <<- y
inv <<- NULL
}
get <- function() x
setInverse <- function(solveMatrix) inv <<- solveMatrix
getInverse <- function() inv
list(set = set, get = get, setInverse = setInverse, getInverse = getInverse)
}
## This function computes the inverse of the special "matrix" returned by makeCacheMatrix function above
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
inv <- x$getInverse()
if(!is.null(inv)){
message("getting cached data")
return(inv)
}
data <- x$get()
inv <- solve(data,...)
x$setInverse(inv)
inv
}
m <- matrix(rnorm(16),4,4)
m1 <- makeCacheMatrix(m)
cacheSolve(m1)
#install.packages("jsonlite")
library(jsonlite)
#install.packages("httpuv")
library(httpuv)
#install.packages("httr")
library(httr)
# Can be github, linkedin etc depending on application
oauth_endpoints("github")
# Change based on what you
myapp <- oauth_app(appname = "dataclean",
key = "Iv1.55af46da5ec3fb30",
secret = "839cb8299e52acbae06c8e9865df9effdca2a397")
# Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(jsonlite)
#install.packages("jsonlite")
library(jsonlite)
#install.packages("httpuv")
library(httpuv)
#install.packages("httr")
library(httr)
# Can be github, linkedin etc depending on application
oauth_endpoints("github")
# Change based on what you
myapp <- oauth_app(appname = "dataclean",
key = "Iv1.55af46da5ec3fb30",
secret = "839cb8299e52acbae06c8e9865df9effdca2a397")
# Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
# Use API
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
# Take action on http error
stop_for_status(req)
# Extract content from a request
json1 = content(req)
# Convert to a data.frame
gitDF = jsonlite::fromJSON(jsonlite::toJSON(json1))
# Subset data.frame
gitDF[gitDF$full_name == "jtleek/datasharing", "created_at"]
library(jsonlite)
library(httpuv)
install(httpuv)
installed.packages("httpuv")
install.packages("httpuv")
install.packages("httr")
install.packages("httr")
install.packages("httr")
install.packages("httr")
install.packages("httr")
install.packages("httr")
install.packages("httr")
install.packages("httr")
install.packages("sqldf")
library(swirl)
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(mean(size))
summarize(cran, mean(size))
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count>679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc by count)
top_counts_sorted <- arrange(top_counts, desc by "count")
top_counts_sorted <- arrange(top_counts, desc count)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique>465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
cran %>%
select(ip_id, country, package, size) %>%
print
cran %>%
select(ip_id, country, package, size) %>%
print
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
swirl()
install.packages("curl")
install.packages("curl")
install.packages("curl")
library(data.table)
housing <- data.table::fread("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
housing[VAL == 24, .N]
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
, 'ACS.csv'
, method='curl' )
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
, 'ACS.csv'
)
ACS <- read.csv('ACS.csv')
agricultureLogical <- ACS$ACR == 3 & ACS$AGS == 6
head(which(agricultureLogical), 3)
install.packages("jpeg")
library(jpeg)
library(jpeg)
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
, 'jeff.jpg'
, mode='wb' )
picture <- jpeg::readJPEG('jeff.jpg'
, native=TRUE)
quantile(picture, probs = c(0.3, 0.8) )
library("data.table")
FGDP <- data.table::fread('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
, skip=4
, nrows = 190
, select = c(1, 2, 4, 5)
, col.names=c("CountryCode", "Rank", "Economy", "Total")
)
FEDSTATS_Country <- data.table::fread('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
)
mergedDT <- merge(FGDP, FEDSTATS_Country, by = 'CountryCode')
nrow(mergedDT)
q()
librarr(swirl)
library(swirl)
swirl()
swirl()
download.file(https://www.google.com)
download.file("https://www.google.com")
download.file("https://www.google.com", destfile = default)
download.file("https://www.google.com", destfile = default.stringsAsFactors())
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes = index(amzn)
amzn <- getSymbols("AMZN",auto.assign=FALSE)
sampleTimes <- index(amzn)
DF <- table(Year = year(sampleTimes), weekdays(sampleTimes)) %>%
addmargins(FUN = list(Total = sum), quiet = TRUE) %>%
as.data.frame
library(swirl)
swirl()
swirl()
swirl::install_course("Exploratory Data Analysis")
library(swirl)
swirl()
swirl()
install.packages(ggplot2)
install.packages(ggplot)
install.packages("ggplot2")
library(swirl)
swirl()
swirl()
library(data.table)
setwd("E:/coursera/ds_specialization/course4_exploratoryda/week/ExData_Plotting1")
setwd("E:/coursera/ds_specialization/course4_exploratoryda/week/ExData_Plotting1")
setwd("E:/coursera/ds_specialization/course4_exploratoryda/week/ExData_Plotting1")
setwd("E:/coursera/ds_specialization/course4_exploratoryda/week1/ExData_Plotting1")
library("data.table")
#load package
library(data.table)
#read data from text file
readtext <- data.table::fread(input = "household_power_consumption.txt", na.strings="?" )
#subsetting data for specified time
data <- readtext[readtext$Date %in% c("1/2/2007","2/2/2007") ,]
#plot1
globalActivePower <- as.numeric(data$Global_active_power)
png("plot1.png", width=480, height=480)
hist(globalActivePower, col="red", main="Global Active Power", xlab="Global Active Power (kilowatts)")
dev.off()
#load package
library(data.table)
#read data from text file
readtext <- data.table::fread(input = "household_power_consumption.txt", na.strings="?" )
#subsetting data for specified time
data <- readtext[readtext$Date %in% c("1/2/2007","2/2/2007") ,]
#plot1
globalActivePower <- as.numeric(data$Global_active_power)
png("plot1.png", width=480, height=480)
hist(globalActivePower, col="red", main="Global Active Power", xlab="Global Active Power (kilowatts)")
dev.off()
#reading data from text file
readtext <- data.table::fread(input = "household_power_consumption.txt", na.strings="?" )
#subsetting data for required timeline
data <- readtext[readtext$Date %in% c("1/2/2007","2/2/2007") ,]
#plot2
datetime <- strptime(paste(data$Date, data$Time, sep=" "), "%d/%m/%Y %H:%M:%S")
globalActivePower <- as.numeric(data$Global_active_power)
png("plot2.png", width=480, height=480)
plot(datetime, globalActivePower, type="l", xlab="", ylab="Global Active Power (kilowatts)")
dev.off()
readtext <- data.table::fread(input = "household_power_consumption.txt", na.strings="?" )
data <- readtext[readtext$Date %in% c("1/2/2007","2/2/2007") ,]
datetime <- strptime(paste(data$Date, data$Time, sep=" "), "%d/%m/%Y %H:%M:%S")
globalActivePower <- as.numeric(data$Global_active_power)
subMetering1 <- as.numeric(data$Sub_metering_1)
subMetering2 <- as.numeric(data$Sub_metering_2)
subMetering3 <- as.numeric(data$Sub_metering_3)
png("plot3.png", width=480, height=480)
plot(datetime, subMetering1, type="l", ylab="Energy Submetering", xlab="")
lines(datetime, subMetering2, type="l", col="red")
lines(datetime, subMetering3, type="l", col="blue")
legend("topright", c("Sub_metering_1", "Sub_metering_2", "Sub_metering_3"), lty=1, lwd=2.5, col=c("black", "red", "blue"))
dev.off()
#reading data fromtext file
readtext <- data.table::fread(input = "household_power_consumption.txt", na.strings="?" )
#subsetting data for required timeline
data <- readtext[readtext$Date %in% c("1/2/2007","2/2/2007") ,]
#plot4
datetime <- strptime(paste(data$Date, data$Time, sep=" "), "%d/%m/%Y %H:%M:%S")
globalActivePower <- as.numeric(data$Global_active_power)
globalReactivePower <- as.numeric(data$Global_reactive_power)
voltage <- as.numeric(data$Voltage)
subMetering1 <- as.numeric(data$Sub_metering_1)
subMetering2 <- as.numeric(data$Sub_metering_2)
subMetering3 <- as.numeric(data$Sub_metering_3)
png("plot4.png", width=480, height=480)
par(mfrow = c(2, 2))
plot(datetime, globalActivePower, type="l", xlab="", ylab="Global Active Power", cex=0.2)
plot(datetime, voltage, type="l", xlab="datetime", ylab="Voltage")
plot(datetime, subMetering1, type="l", ylab="Energy Submetering", xlab="")
lines(datetime, subMetering2, type="l", col="red")
lines(datetime, subMetering3, type="l", col="blue")
legend("topright", c("Sub_metering_1", "Sub_metering_2", "Sub_metering_3"), lty=, lwd=2.5, col=c("black", "red", "blue"), bty="o")
plot(datetime, globalReactivePower, type="l", xlab="datetime", ylab="Global_reactive_power")
dev.off()
